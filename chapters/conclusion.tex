Based on the analysis and findings of this seminar paper, it is evident that though sparsity-based estimators (SBEs) like Lasso regression are good for high-dimensional data, they are also very sensitive to normalization choices. Our experiments agreed to the main paper findings that SBEs can be unreliable, especially in higher dimensional scenarios, where normalization decisions can significantly impact predictive accuracy and model stability. However, our tests also showed that these might actually not affect model explainability. Our results also highlighted the possible impacts in predictive accuracy of the models in a machine learning contexts. Moreover, the results highlight that is is important to think carefully about how the choice of hyperparameters, preprocessing methods, and different normalization strategies, especially in empirical applications like economics and social sciences, where the fragility of estimates can have substantial implications.  For more confidence in these results, more experiments in different contexts should be done for evaluating the impacts of these estimators in different contexts. Nevertheless, future research should focus on developing more reliable estimators that are more robust, ensuring greater reliability across different applications and contexts.\\

\textcolor{blue}{moreoever there are so many choices to make and each of these choices can affect our estimates and thereby our results as a whole!  
 Each dataset comes with its limitations and complexities which limits the generalizability of these tests.Also mention that it behaves differently in different places, which complicates it but at least it highlights the fact that it is still super fragile}