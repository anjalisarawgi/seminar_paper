The use of Sparsity-Based Estimators (SBEs), such as lasso regression has gained significant attention in statistics and econometrics due to their ability to handle high dimensional data, where the number of potential predictors often exceeds the number of observations. Traditional estimation techniques like Ordinary Lease Squares (OLS) become impractical in such scenarios. SBEs address this by assuming that only a few of the predictors affect the outcome, allowing for more efficient variable selection and model simplification, particularly when the true model is sparse.\\
\\
However, the assumptions underlying these Sparsity-Based Estimators (SBEs), particularly the sparsity assumption have been questioned. This assumption, which suggests that only a small subset of the many potential variables affect the outcome, may not always hold, potentially compromising the reliability of SBEs in practice. Moreover, the performance of SBEs is sensitive to various methodological choices, such as the construction of the control matrix, the choice of tuning parameters, and the method of normalization, all of which can introduce bias or reducing efficiency. \\
\\
This seminar paper is centered around the findings of the paper "The Fragility of Sparsity", which critically examines the robustness of SBEs in various empirical contexts. Specifically, "The Fragility of Sparsity" highlights the sensitivity of SBEs to the assumptions and methodological choices made during model specification, raising concerns about their reliability. \\
\\
Building on this, my seminar paper investigates these concerns in detail, focusing on the empirical validity of the sparsity assumption and the robustness of SBEs to different normalization choices. To extend the discussion, I conduct experiments applying SBEs to a new dataset to test whether the issues highlighted in "The Fragility of Sparsity" also are true in different contexts. Furthermore, I experimented with different dataset sizes and aimed to evaluate whether SBEs affect prediction accuracy or loss in machine learning context. Additionally, I explored how varying the number of covariates and the regularization parameter for Lasso influences the behaviour of these estimates. This empirical work aims to validate and explore the generalizability of existing findings and to explore how SBEs perform in a real-world data scenarios.

